{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas_profiling\n",
      "  Downloading pandas_profiling-3.1.0-py2.py3-none-any.whl (261 kB)\n",
      "Requirement already satisfied: PyYAML>=5.0.0 in c:\\users\\christine\\anaconda3\\lib\\site-packages (from pandas_profiling) (5.3.1)\n",
      "Collecting tqdm>=4.48.2\n",
      "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "Collecting missingno>=0.4.2\n",
      "  Downloading missingno-0.5.1-py3-none-any.whl (8.7 kB)\n",
      "Collecting pydantic>=1.8.1\n",
      "  Downloading pydantic-1.9.0-cp38-cp38-win_amd64.whl (2.1 MB)\n",
      "Collecting tangled-up-in-unicode==0.1.0\n",
      "  Downloading tangled_up_in_unicode-0.1.0-py3-none-any.whl (3.1 MB)\n",
      "Collecting visions[type_image_path]==0.7.4\n",
      "  Downloading visions-0.7.4-py3-none-any.whl (102 kB)\n",
      "Requirement already satisfied: matplotlib>=3.2.0 in c:\\users\\christine\\anaconda3\\lib\\site-packages (from pandas_profiling) (3.2.2)\n",
      "Collecting phik>=0.11.1\n",
      "  Downloading phik-0.12.2-cp38-cp38-win_amd64.whl (677 kB)\n",
      "Requirement already satisfied: requests>=2.24.0 in c:\\users\\christine\\anaconda3\\lib\\site-packages (from pandas_profiling) (2.24.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\christine\\anaconda3\\lib\\site-packages (from pandas_profiling) (1.5.0)\n",
      "Collecting markupsafe~=2.0.1\n",
      "  Downloading MarkupSafe-2.0.1-cp38-cp38-win_amd64.whl (14 kB)\n",
      "Collecting htmlmin>=0.1.12\n",
      "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
      "Requirement already satisfied: seaborn>=0.10.1 in c:\\users\\christine\\anaconda3\\lib\\site-packages (from pandas_profiling) (0.10.1)\n",
      "Collecting multimethod>=1.4\n",
      "  Downloading multimethod-1.8-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\christine\\anaconda3\\lib\\site-packages (from pandas_profiling) (1.18.5)\n",
      "Collecting joblib~=1.0.1\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "Requirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3 in c:\\users\\christine\\anaconda3\\lib\\site-packages (from pandas_profiling) (1.0.5)\n",
      "Requirement already satisfied: jinja2>=2.11.1 in c:\\users\\christine\\anaconda3\\lib\\site-packages (from pandas_profiling) (2.11.2)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\christine\\anaconda3\\lib\\site-packages (from tqdm>=4.48.2->pandas_profiling) (0.4.3)\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Downloading typing_extensions-4.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: networkx>=2.4 in c:\\users\\christine\\anaconda3\\lib\\site-packages (from visions[type_image_path]==0.7.4->pandas_profiling) (2.4)\n",
      "Requirement already satisfied: attrs>=19.3.0 in c:\\users\\christine\\anaconda3\\lib\\site-packages (from visions[type_image_path]==0.7.4->pandas_profiling) (19.3.0)\n",
      "Collecting imagehash; extra == \"type_image_path\"\n",
      "  Downloading ImageHash-4.2.1.tar.gz (812 kB)\n",
      "Requirement already satisfied: Pillow; extra == \"type_image_path\" in c:\\users\\christine\\anaconda3\\lib\\site-packages (from visions[type_image_path]==0.7.4->pandas_profiling) (7.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\christine\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.0->pandas_profiling) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\christine\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.0->pandas_profiling) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\christine\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.0->pandas_profiling) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\christine\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.0->pandas_profiling) (0.10.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\christine\\anaconda3\\lib\\site-packages (from requests>=2.24.0->pandas_profiling) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\christine\\anaconda3\\lib\\site-packages (from requests>=2.24.0->pandas_profiling) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\christine\\anaconda3\\lib\\site-packages (from requests>=2.24.0->pandas_profiling) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\christine\\anaconda3\\lib\\site-packages (from requests>=2.24.0->pandas_profiling) (2.10)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\christine\\anaconda3\\lib\\site-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3->pandas_profiling) (2020.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\christine\\anaconda3\\lib\\site-packages (from networkx>=2.4->visions[type_image_path]==0.7.4->pandas_profiling) (4.4.2)\n",
      "Requirement already satisfied: six in c:\\users\\christine\\anaconda3\\lib\\site-packages (from imagehash; extra == \"type_image_path\"->visions[type_image_path]==0.7.4->pandas_profiling) (1.15.0)\n",
      "Requirement already satisfied: PyWavelets in c:\\users\\christine\\anaconda3\\lib\\site-packages (from imagehash; extra == \"type_image_path\"->visions[type_image_path]==0.7.4->pandas_profiling) (1.1.1)\n",
      "Building wheels for collected packages: htmlmin, imagehash\n",
      "  Building wheel for htmlmin (setup.py): started\n",
      "  Building wheel for htmlmin (setup.py): finished with status 'done'\n",
      "  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27090 sha256=ad359acf190abad9756a9fe139e99df98e1b512984a9330bc776ae456440a3e8\n",
      "  Stored in directory: c:\\users\\christine\\appdata\\local\\pip\\cache\\wheels\\23\\14\\6e\\4be5bfeeb027f4939a01764b48edd5996acf574b0913fe5243\n",
      "  Building wheel for imagehash (setup.py): started\n",
      "  Building wheel for imagehash (setup.py): finished with status 'done'\n",
      "  Created wheel for imagehash: filename=ImageHash-4.2.1-py2.py3-none-any.whl size=295204 sha256=a633f2404d1b493ad4f90aa65e7fc572941233d029042f3d306cdce9321d6662\n",
      "  Stored in directory: c:\\users\\christine\\appdata\\local\\pip\\cache\\wheels\\48\\a1\\7f\\096c1269d6bf78d4768180602579b35a1e8cb1250bb4b40c74\n",
      "Successfully built htmlmin imagehash\n",
      "Installing collected packages: tqdm, missingno, typing-extensions, pydantic, tangled-up-in-unicode, multimethod, imagehash, visions, joblib, phik, markupsafe, htmlmin, pandas-profiling\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.47.0\n",
      "    Uninstalling tqdm-4.47.0:\n",
      "      Successfully uninstalled tqdm-4.47.0\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.2\n",
      "    Uninstalling typing-extensions-3.7.4.2:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.2\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 0.16.0\n",
      "    Uninstalling joblib-0.16.0:\n",
      "      Successfully uninstalled joblib-0.16.0\n",
      "  Attempting uninstall: markupsafe\n",
      "    Found existing installation: MarkupSafe 1.1.1\n",
      "    Uninstalling MarkupSafe-1.1.1:\n",
      "      Successfully uninstalled MarkupSafe-1.1.1\n",
      "Successfully installed htmlmin-0.1.12 imagehash-4.2.1 joblib-1.0.1 markupsafe-2.0.1 missingno-0.5.1 multimethod-1.8 pandas-profiling-3.1.0 phik-0.12.2 pydantic-1.9.0 tangled-up-in-unicode-0.1.0 tqdm-4.64.0 typing-extensions-4.2.0 visions-0.7.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: phik 0.12.2 has requirement scipy>=1.5.2, but you'll have scipy 1.5.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas_profiling  \n",
    "from pandas_profiling import ProfileReport\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad070bc81bf48b39821d3774bfd5845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f23099cf9c4b9191bd18d305896f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37473761c39e45f69b687053a8254fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf82e3e9a7d14aee8661001b8536aa69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#data profiling\n",
    "df = pd.read_csv('covid_restaurant_full.csv')\n",
    "df_loc = pd.read_csv('covid_restaurant_full_loc.csv')\n",
    "profile = df.profile_report(title='Full Data Profiling')\n",
    "#export as html file\n",
    "profile.to_file(output_file=\"Full Data Profiling.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34117, 61)\n",
      "(31715, 61)\n",
      "(31715, 65)\n"
     ]
    }
   ],
   "source": [
    "#Based on results from the report, remove duplicates\n",
    "print(df.shape)\n",
    "df2 = df.drop_duplicates()\n",
    "df_loc_2 = df_loc.drop_duplicates()\n",
    "print(df2.shape)\n",
    "#Duplicates won't drop in this version of dataset since it includes up to fips zip and not just state and area\n",
    "print(df_loc_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5236268683293631\n",
      "0.8737431864434867\n",
      "0.9436643320423324\n",
      "-0.5332274394799003\n",
      "-0.5706826463616347\n",
      "0.935305426006936\n",
      "0.6264971563856977\n",
      "-0.5812055390563952\n",
      "0.4987345927935435\n",
      "-0.4388564085488304\n"
     ]
    }
   ],
   "source": [
    "#Based on results from report, examine some of the correlated variables more deeply and decide to drop or not\n",
    "print(df2['total_restaurants_zip'].corr(df2['Total_Reviews_Zip']))\n",
    "print(df2['Rural_urban_continuum_code_2013'].corr(df2['Urban_influence_code_2013'])) #.94 correlation, should remove\n",
    "\n",
    "print(df2['Unemployment_rate_2020'].corr(df2['Median_Household_Income_2019']))\n",
    "print(df2['Unemployment_rate_2020'].corr(df2['Med_HH_Income_Percent_of_State_Total_2019']))\n",
    "print(df2['Median_Household_Income_2019'].corr(df2['Med_HH_Income_Percent_of_State_Total_2019'])) #.93 correlation, should remove\n",
    "\n",
    "print(df2['Unemployment_rate_2020'].corr(df2['covid_moderate']))\n",
    "print(df2['Unemployment_rate_2020'].corr(df2['covid_substantial']))\n",
    "print(df2['Median_Household_Income_2019'].corr(df2['covid_substantial']))\n",
    "print(df2['Median_Household_Income_2019'].corr(df2['covid_moderate']))\n",
    "\n",
    "#From the report, many of the economic location/variables seem correlated with one another. Will run a VIF in a later step to \n",
    "#help better determine which ones to remove, for now keep them in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5236268683293631\n",
      "0.39230375616447377\n",
      "0.3346637424528914\n",
      "0.4882328490126407\n",
      "0.409131943557723\n"
     ]
    }
   ],
   "source": [
    "#Based on results from report, examine some of the highly correlated category variables\n",
    "print(df2['sushi'].corr(df2['japanese']))\n",
    "print(df2['hotdogs'].corr(df2['burgers']))\n",
    "print(df2['italian'].corr(df2['pizza']))\n",
    "print(df2['bars'].corr(df2['sportsbars']))\n",
    "print(df2['bars'].corr(df2['juicebars']))\n",
    "\n",
    "#Only sushi seems a bit high, remove sushi\n",
    "df2 = df2.drop(['sushi'], axis=1)\n",
    "df_loc_2 = df_loc_2.drop(['sushi'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write to csv\n",
    "df2.to_csv('covid_restaurant_full_post_profiling.csv')\n",
    "df_loc_2.to_csv('covid_restaurant_full_post_profiling_loc.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
